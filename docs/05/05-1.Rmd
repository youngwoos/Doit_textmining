---
title: "Do it! 쉽게 배우는 R 텍스트 마이닝 - 05 의미망 분석: <br> 어떤 맥락에서 단어를 썼을까?"
author: "김영우"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "../css/custom.css"]
    lib_dir: libs
    chakra: ../libs/remark-latest.min.js
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: '16:10'
      navigation:
        scroll: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, 
        width = 80,
        # width = 70,
        
        max.print = 80,
        tibble.print_max = 40,
        
        tibble.width = 80,
        # tibble.width = 70,
        
        # pillar.min_chars = Inf, # tibble 문자 출력 제한
        servr.interval = 0.01) # Viewer 수정 반영 속도


knitr::opts_chunk$set(cache = T, warning = F, message = F, 
                      dpi = 300, fig.height = 4)
                      # out.width = "100%"

xaringanExtra::use_tile_view()

library(knitr)
library(icon)
library(here)
```


```{r echo=FALSE}
rm(list = ls())

library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
showtext_opts(dpi = 300) # opts_chunk$set(dpi=300)

# code highlighting
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})


```


class: title0

Do it! 쉽게 배우는 R 텍스트 마이닝

---

class: no-page-num

<br>

.pull-left[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("https://raw.githubusercontent.com/youngwoos/Doit_textmining/main/cover.png")
```
]

.pull-right[

<br>
<br>
<br>

`r fontawesome("github")` [github.com/youngwoos/Doit_textmining](https://github.com/youngwoos/Doit_textmining)

`r fontawesome("facebook-square")` [facebook.com/groups/datacommunity](https://facebook.com/groups/datacommunity)

- [네이버책](https://book.naver.com/bookdb/book_detail.nhn?bid=17891971)
  - [yes24](http://bit.ly/3oUuJOB)
  - [알라딘](http://bit.ly/3oXOSDn)
  - [교보문고](https://bit.ly/2LtNOcB)
]

---

class: title0

05 의미망 분석: <br> 어떤 맥락에서 단어를 썼을까?

---

class: title0-2

We'll make

<br-back-20>

```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("../Image/05/05_2_6.png")
```

---

class: title0-2

We'll make

<br-back-20>

```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("../Image/05/05_3_2.png")
```

---

class: title0-2

and

<br-back-40>

```{r, echo=F, out.width="65%", out.height="65%"}
include_graphics("../Image/05/05_4_2.png")
```

---

<br>

.large2[.font-jua[목차]]

.large[.font-jua[05-1 동시 출현 단어 분석 - Co-occurrence analysis]]([link](#05-1))

.large[.font-jua[05-2 동시 출현 네트워크 - Co-occurrence network]]([link](#05-2))

.large[.font-jua[05-3 단어 간 상관 분석 - Phi coefficient]]([link](#05-3))

.large[.font-jua[05-4 연이어 사용된 단어쌍 분석 - n-gram]]([link](#05-4))


---

name: 05-1
class: title1

05-1 동시 출현 단어 분석:  
Co-occurrence analysis

---

##### 동시 출현 단어 분석(Co-occurrence analysis)

- 단어 간의 관계를 살펴보는 분석 방법
- '손-장갑', '머리-모자' 처럼 관계가 있는 단어 파악
- 단어의 관계를 표현한 의미망(semantic network) 만드는데 활용


---

#### 기본적인 전처리


```{r eval=F}
# 기생충 기사 댓글 불러오기
library(readr)
raw_news_comment <- read_csv("news_comment_parasite.csv")

# 전처리
library(dplyr)
library(stringr)
library(textclean)

news_comment <- raw_news_comment %>%
  select(reply) %>%
  mutate(reply = str_replace_all(reply, "[^가-힣]", " "),
         reply = str_squish(reply),
         id = row_number())
```

```{r echo=F}
library(readr)
library(dplyr)
library(stringr)
library(textclean)

# 기생충 기사 댓글 불러오기
raw_news_comment <- read_csv("../../Data/news_comment_parasite.csv")

news_comment <- raw_news_comment %>%
  select(reply) %>%
  mutate(reply = str_replace_all(reply, "[^가-힣]", " "),
         reply = str_squish(reply),
         id = row_number())
```

---

#### 토큰화하기

- 단어가 사용된 맥락을 살펴봐야 하므로 명사, 형용사, 동사 함께 추출

##### 1. 형태소 분석기를 이용해 품사 기준으로 토큰화하기

- `SimplePos22()` : 문장의 단어를 22개의 품사로 구분

```{r SimplePos22, eval=F}
library(tidytext)
library(KoNLP)

comment_pos <- news_comment %>%
  unnest_tokens(input = reply,
                output = word,
                token = SimplePos22,
                drop = F)

comment_pos %>%
  select(reply, word)
```

---

```{r ref.label="SimplePos22", R.options=list(tibble.width = 50), echo=F}

```

---

##### 품사 분리하여 행 구성하기

- 원하는 품사를 추출하기 쉽도록 한 행을 한 품사로 구성하기
- `tidyr::separate_rows()`:
  - 정규 표현식에 따라 텍스트를 여러 행으로 나누기
  - `sep  = "[+]"`: `"+"`가 등장할 때마다 행을 나눔

```{r comment_pos, R.options=list(tibble.width = 50), eval=F}
# 품사별로 행 분리
library(tidyr)
comment_pos <- comment_pos %>%
  separate_rows(word, sep = "[+]")

comment_pos %>%
  select(word, reply)
```

---

```{r ref.label="comment_pos", R.options=list(tibble.width = 50), echo=F}

```

---

##### 3. 품사 추출하기

<br10>

##### (1) 명사 추출하기

- `"/n"`이 붙어있는 단어 추출
- 태그 제거: '/로 시작하는 모든 문자' 제거

```{r noun, R.options=list(tibble.width = 50), eval=F}
# 명사 추출하기
noun <- comment_pos %>%
  filter(str_detect(word, "/n")) %>%
  mutate(word = str_remove(word, "/.*$"))

noun %>%
  select(word, reply)
```

---

```{r ref.label="noun", R.options=list(tibble.width = 50), echo=F}
```

---


```{r}
# 명사 빈도 구하기
noun %>%
  count(word, sort = T)
```

---


##### (2) 동사, 형용사 추출하기

- 동사 `"/pv"`, 형용사:`"/pa"` 붙어있는 단어 추출
- 단어 뒤에 태그 대신 '다'를 붙여 이해하기 편하게 수정하기
  - ex) "받" → "받다", "멋지" → "멋지다"

```{r pvpa, R.options=list(tibble.width = 50), eval=F}
# 동사, 형용사 추출하기
pvpa <- comment_pos %>%
  filter(str_detect(word, "/pv|/pa")) %>%         # "/pv", "/pa" 추출
  mutate(word = str_replace(word, "/.*$", "다"))  # "/"로 시작 문자를 "다"로 바꾸기

pvpa %>%
  select(word, reply)
```

---

```{r ref.label="pvpa", R.options=list(tibble.width = 50, width = 60), echo=F}
```

---

##### (3) 추출한 데이터 결합하기

- 추출한 단어 결합하기
- 이해할 수 있는 두 글자 이상 단어만 남기기

```{r comment, R.options=list(tibble.width = 50), eval=F}
# 품사 결합
comment <- bind_rows(noun, pvpa) %>%
  filter(str_count(word) >= 2) %>%
  arrange(id)

comment %>%
  select(word, reply)
```

---

```{r ref.label="comment", R.options=list(tibble.width = 50), echo=F}
```

---

.box[
  .info[`r icon_style(fontawesome("rocket"), fill = "#FF7333")` 명사, 동사, 형용사를 한 번에 추출하기]

  - 명사, 동사, 형용사를 추출해 결합한 후 두 글자 이상만 남기기

```{r eval=F}
comment_new <- comment_pos %>%
  separate_rows(word, sep = "[+]") %>%
  filter(str_detect(word, "/n|/pv|/pa")) %>%
  mutate(word = ifelse(str_detect(word, "/pv|/pa"),
                       str_replace(word, "/.*$", "다"),
                       str_remove(word, "/.*$"))) %>%
  filter(str_count(word) >= 2) %>%
  arrange(id)
```
]



---



#### 단어 동시 출현 빈도 구하기

- `widyr::pairwise_count()`
  - `item`: 단어
  - `feature`: 텍스트 구분 기준
  - `sort = T`: 빈도가 높은 순으로 출력 결과 정렬

```{r eval=F}
install.packages("widyr")
library(widyr)

pair <- comment %>%
  pairwise_count(item = word,
                 feature = id,
                 sort = T)
pair
```

---

```{r pair, echo=F}
library(widyr)

pair <- comment %>%
  pairwise_count(item = word,
                 feature = id,
                 sort = T)
pair
```

--

- 한 단어를 기준으로 함께 사용된 모든 단어의 빈도를 구함
- 순서를 바꿔가며 같은 빈도를 지니는 두 개의 행으로 구성됨
  - ex) "영화-기생충", "기생충-영화"

---


##### 특정 단어와 자주 함께 사용된 단어 살펴보기


.pull-left[

```{r}
pair %>% filter(item1 == "영화")
```
]

.pull-right[


```{r}
pair %>% filter(item1 == "봉준호")
```
]


```{r, echo=F}
save(pair, comment, news_comment, comment_pos, file = "05-1.rdata")
```

