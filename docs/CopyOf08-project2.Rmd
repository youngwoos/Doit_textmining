---
output:
  word_document: 
    fig_height: 6
    fig_width: 8
    reference_docx: "../template/WordTemplate_EasyR_Text.docx"
    toc: true
    toc_depth: 2
toc-title: "목차"
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::knit_child("../rmd_etc/rmd_options.Rmd")

options(tibble.print_min = 5,  # 행 출력 제한
        tibble.print_max = 5)  # 행 출력 제한
```

```{r include=F}
# 폰트 설정
library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()

# 출력 결과 제한 함수
source(here::here("rmd_etc/func_chunk_print_limit.R"))

showtext_opts(dpi = 96)
```


# 8. 텍스트 마이닝 프로젝트: 차기 대선 주자 SNS 여론 파악

이낙연 의원과 이재명 경기도지사가 20대 대통령 선거의 유력한 후보로 거론되고 있습니다. 이 장에서는 사람들이 두 차기 후보에 대해 어떤 생각을 가지고 있는지 SNS 데이터를 분석해 알아보겠습니다.


## 8.1 SNS 언급량 추이

우선 SNS에서 사람들이 어떤 후보를 더 많이 언급하는지 알아보겠습니다. 데이터를 불러와 전처리한 뒤 두 후보의 언급량 추이를 비교하겠습니다.

### 8.1.1 기본적인 전처리

`"tweet_nak.csv"`와 `"tweet_jae.csv"`에는 각각 2020년 8월 13일~21일까지 이낙연 의원과 이재명 경기도지사를 언급한 트위터 데이터가 담겨있습니다. 데이터를 불러와 결합한 다음 전처리를 하겠습니다. 

`glimpse(bind_tweet)`를 실행하면 `bind_tweet`이 13,928개의 트윗으로 구성되어 있음을 알 수 있습니다. 두 후보를 함께 언급한 트윗이 있기 때문에 `bind_tweet`에는 중복된 행이 포함되어 있습니다.

```{r eval=F}
# 데이터 불러오기
library(dplyr)
library(readr)
bind_tweet <- bind_rows(
  read_csv("tweet_nak.csv") %>% mutate(candidate = "이낙연"),
  read_csv("tweet_jae.csv") %>% mutate(candidate = "이재명"))

glimpse(bind_tweet)
```

```{r echo=F}
# 데이터 불러오기
library(dplyr)
library(readr)
bind_tweet <- bind_rows(
  read_csv(here::here("files/tweet_nak.csv")) %>% mutate(candidate = "이낙연"),
  read_csv(here::here("files/tweet_jae.csv")) %>% mutate(candidate = "이재명"))

glimpse(bind_tweet, width = 60)
```

`bind_tweet`의 `text`에 분석할 텍스트가 들어있습니다. 분석에 적합하도록 다음과 같은 전처리를 하겠습니다.


**사용자 아이디 태그 제거하기** : 트윗에는 `"@userid"`와 같이 `@`를 이용해 사용자 아이디를 언급한 텍스트가 포함되어 있습니다. `textclean` 패키지의 `replace_tag()`를 이용해 아이디 태그를 제거하겠습니다. 이때 `str_to_lower()`는 대문자를 처리하지 못하기 때문에 `stringr` 패키지의 `str_to_lower()`를 이용해 소문자로 변환한 다음 `replace_tag()`에 적용해야 합니다.

**html 태그 제거하기** : 트윗에는 html 특수 문자가 포함되어 있어서 출력하면 내용을 알아보기 불편합니다. `textclean` 패키지의 `replace_html()`을 이용해 html 특수 문자를 제거한 다음 `stringr` 패키지의 `str_squish()`를 이용해 중복 공백을 제거하겠습니다.

**날짜 변수 만들기** : `bind_tweet`의 `created_at`은 트윗을 작성한 시각이 '년월일시분초' 단위로 기록되어 있습니다. `lubridate` 패키지의 `date()`를 이용해 '년월일'을 추출해 `date` 변수를 만들겠습니다. `date`는 트윗을 날짜별로 분석할 때 활용합니다.

**광고 트윗 제거하기** : 트위터에는 유력 정치인 이름과 같이 주목받는 키워드를 넣은 광고가 많습니다. 그리고 광고에는 대부분 URL 링크가 있습니다. 광고 트윗을 제거하기 위해 `"https://"`가 포함된 텍스트를 제거하겠습니다.

**중복 글 제거하기** : 같은 트윗을 한 사용자나 여러 사용자가 반복 게시하는 경우가 있습니다. `bind_tweet`을 `candidate`별로 분리한 다음 `distinct()`를 이용해 `text`를 추출하겠습니다. 이렇게 하면 내용이 같은 글은 `candidate` 별로 하나씩만 남습니다.

**어뷰징 트윗 제거하기** : 트위터에는 극단적으로 트윗을 많이 올리는 사용자가 있습니다. 이런 사용자가 작성한 트윗을 모두 포함하면 분석 결과에 소수의 의견이 과도하게 반영됩니다. `bind_tweet`을 `"candidate"`, `"date"`, `"screen_name"`별로 분리한 다음 `slice_sample()`을 이용해 5개씩 추출하겠습니다. 이렇게 하면 트윗이 사용자당 하루 최대 5개만 남기 때문에 소수의 견해가 과도하게 반영되는 문제를 막을 수 있습니다.

다음 코드를 실행해 `glimpse(tweet)`의 결과를 보면 분석에 적합한 8,337행이 추출됐음을 알 수 있습니다.

```{r eval=F}
install.packages("lubridate")
library(lubridate)
library(textclean)
library(stringr)
```

```{r echo=F}
# install.packages("lubridate")
library(lubridate)
library(textclean)
library(stringr)
```

```{r}
set.seed(1234)
tweet <- bind_tweet %>%

  mutate(text = replace_tag(str_to_lower(text)),  # id 태그 제거
         text = str_squish(replace_html(text)),   # html 특수 문자 제거
         date = date(created_at)) %>%             # 날짜 변수 생성

  filter(!str_detect(text, "https://")) %>%       # 광고 트윗 제거

  group_by(candidate) %>%                         # 중복 글 제거
  distinct(text, .keep_all = T) %>%

  group_by(candidate, date, screen_name) %>%      # 사용자별 하루 최대 5개 추출
  slice_sample(n = 5) %>%
  ungroup()
```


```{r eval=F}
glimpse(tweet)
```

```{r echo=F}
glimpse(tweet, width = 60)
```


### 8.1.2 트윗 빈도 추이


#### 1. 트윗 빈도 추이 선 그래프

날짜별로 빈도를 분석해 어떤 후보를 언급한 트윗이 많은지 추이를 알아보겠습니다. `date`, `candidate`별 트윗 빈도를 구한 다음 선 그래프를 만들겠습니다.

```{r}
# 날짜, 후보별 빈도
frequency_date <- tweet %>%
  count(date, candidate)

frequency_date

# 선 그래프
library(ggplot2)
ggplot(frequency_date, aes(x = date, y = n, col = candidate)) +
  geom_line()
```


#### 그래프 다듬기

`ggplot2` 패키지의 함수를 이용해 그래프를 보기 좋게 수정하겠습니다. 그래프를 만들 때 두 후보를 표현할 색상 코드(Hex Color Code) 목록을 만들어 활용하겠습니다. 이 목록은 이후로도 그래프의 색깔을 정할 때 반복 활용합니다.

```{r}
# 후보 색상 목록 생성
col_candidate <- c("#619CFF", "#B79F00")

ggplot(frequency_date, aes(x = date, y = n, col = candidate)) +  
  geom_line(size = 1) +
  geom_point(size = 2) +
  
  scale_x_date(date_labels = "%m/%d",                         # x축 날짜 포맷
               date_breaks  = "1 day") +                      # x축 날짜 간격
  scale_y_continuous(limits = c(0, 1200),                     # y축 범위
                     breaks = seq(0, 1200, 300)) +            # y축 간격
  scale_color_manual(values = col_candidate) +                # 선 색깔
  
  labs(title = "차기 대선주자 트위터 언급량 추이",            # 그래프 제목
       subtitle = "2020.8.13 ~ 2020.8.21",                    # 보조 제목
       x = NULL, y = NULL, col = NULL) +                      # 축 이름 삭제

  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),  # 제목 폰트
        plot.subtitle = element_text(size = 12),              # 부제목 폰트
        panel.grid.minor.x = element_blank())                 # x축 보조축 삭제
```

> [참고] `theme_minimal()`과 같은 테마 적용 함수에 숫자를 입력하면 그래프의 전체 폰트 크기를 조정할 수 있습니다.

<br>

> [편집] 주석 줄맞춤

출력한 그래프를 보면 날짜별로 어떤 후보를 언급한 트윗이 많은지 알 수 있습니다. 전반적으로 이재명 경기도지사를 언급한 트윗이 많고, 18일과 19일에는 이낙연 의원을 언급한 트윗이 더 많았음을 알 수 있습니다.


> [알아두면 좋아요] 색상 코드 알아내기

> `scales` 패키지의 `show_col()`을 이용하면 색상 코드를 알아낼 수 있습니다. 다음 코드를 실행하면 plots 창에 `ggplot2` 패키지가 사용하는 hue Color Palette의 색상 코드를 출력합니다.

```{r, eval=F}
library(scales)
show_col(hue_pal()(6))
```

```{r echo=F, fig.width=6, fig.height=3}
library(scales)
show_col(hue_pal()(6))
```


#### 2. 트윗 빈도 추이 영역 차트

`ggplot2` 패키지의 `geom_area()`를 이용해 **영역 차트(Area chart)**를 만들겠습니다. 영역 차트를 만들면 언급량 차이를 차이를 잘 표현할 수 있습니다. 두 후보의 언급량을 중첩해 표현하도록 `geom_area()`에 `position = "dodge"`를 입력하고, 투명하게 표현하도록 `alpha = 0.6`을 입력하겠습니다.

```{r}
# 영역 그래프
ggplot(frequency_date, aes(x = date, y = n, fill = candidate)) +
  geom_area(position = "dodge", alpha = 0.6)
```

#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
ggplot(frequency_date, aes(x = date, y = n, fill = candidate)) +
  geom_area(position = "dodge", alpha = 0.6) +
  geom_line(size = 0.5, alpha = 0.5) +
  
  scale_x_date(date_labels = "%m/%d", date_breaks  = "1 day") +
  scale_y_continuous(limits = c(0, 1200),
                     breaks = seq(0, 1200, 300)) +
  scale_fill_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 트위터 언급량 추이",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),            
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank())  # y축 보조축 삭제
```

출력한 그래프를 보면 대부분의 날짜에 이재명 경기도지사를 언급한 트윗이 많고, 8월 18일과 19일에만 이낙연 의원을 언급한 트윗이 많다는 것을 쉽게 알 수 있습니다.


## 8.2 SNS 이슈 살펴보기

### 8.2.1 8월 14일의 이슈

앞에서 만든 그래프를 보면 8월 14일에 유독 두 후보의 언급량이 많습니다. 로그 오즈비를 이용해 이날 어떤 일이 있었는지 알아보겠습니다.

#### 1. 띄어쓰기 기준 토큰화

먼저 `tweet`을 띄어쓰기 기준으로 토큰화하겠습니다. 그런 다음 로그 오즈비를 구하고 다른 날짜에 비해 8월 14일에 상대적으로 많이 사용된 단어를 알아보겠습니다.

```{r}
library(tidytext)
library(KoNLP)
word_tweet_raw <- tweet %>%
  unnest_tokens(input = text,
                output = word,
                token = "words",
                drop = F)
```


#### 2. 날짜 분류, 단어별 빈도 구하기

`word_tweet_raw`에 트윗 작성 날짜가 2020년 8월 14일이면 `"target"`, 그렇지 않으면 `"etc"`로 분류한 `category`를 추가하겠습니다. 그런 다음 두 글자 이상 단어를 추출하고 `category`, `word`별 빈도를 구하겠습니다. 다음 코드의 출력 결과를 보면 목표 날짜와 그 외의 날짜에 어떤 단어가 많이 사용됐는지 알 수 있습니다.

```{r}
frequency14 <- word_tweet_raw %>%
  mutate(category = ifelse(date == "2020-08-14", "target", "etc")) %>%
  filter(str_count(word) >= 2) %>%
  count(category, word, sort = T)

frequency14
```

#### 3. 로그 오즈비 구하기

`frequency14`를 Wide form으로 변환해 로그 오즈비를 구하고 `log_odds_ratio`가 높은 순으로 출력하겠습니다. 분모에 `"etc"`, 분자에 `"target"` 날짜의 단어 빈도를 놓고 로그 오즈비를 구했으므로, 목표 날짜에 상대적으로 많이 사용된 단어일수록 `log_odds_ratio`가 큰 값을 지니게 됩니다. 출력 결과에서 `"조사기관"`, `"선호도"`, `"여론조사"` 등을 보면 8월 14일에 지지도 조사와 관련된 일이 있었던 것으로 보입니다.

```{r}
# Wide form으로 변환
library(tidyr)
wide14 <- frequency14 %>%
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = list(n = 0))

# 로그 오즈비 변수 추가
wide14 <- wide14 %>%
  mutate(log_odds_ratio = log(((target + 1) / (sum(target + 1))) /
                                ((etc  + 1) / (sum(etc    + 1)))))
```


```{r}
# log_odds_ratio 높은 순 출력
wide14 %>%
  arrange(-log_odds_ratio) %>%
  head(20) %>%
  print(n = Inf)
```

<!-- ```{r echo=F} -->
<!-- # log_odds_ratio 높은 순 출력 -->
<!-- wide14 %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   head(10) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->



#### 4. 원문 살펴보기

2020년 8월 14일에 `"조사"`를 언급한 트윗을 추출해 내용을 살펴보겠습니다. 다음 코드의 출력 결과를 보면 이날 여론 조사 결과가 발표되었고, 이재명 경기도지사가 이낙연 의원을 처음으로 역전했다는 것을 알 수 있습니다.

```{r eval=F}
# 트윗 내용 확인
tweet %>%
  filter(date == "2020-08-14" & str_detect(text, "조사")) %>%
  head(10) %>%
  pull(text)
```


```{r echo=F}
# 트윗 내용 확인
tweet %>%
  filter(date == "2020-08-14" & str_detect(text, "조사")) %>%
  head(3) %>%
  pull(text)
```

> [편집] 출력 결과 생략, 빈 줄 삭제

<br>

> [참고] 아래 URL에 접속해 구글 검색 결과를 보면 2020년 8월 14일에 차기 대선주자 지지도 조사에서 이재명 경기도지사가 이낙연 의원을 처음으로 역전해 1위를 차지했다는 사실을 확인할 수 있습니다.

> [google.com/search?q=이재명+여론조사%202020.08.14..2020.08.14](https://google.com/search?q=이재명+여론조사%202020.08.14..2020.08.14)



### 8.2.2 8월 18일 ~ 19일의 이슈

**8.1.2**에서 만든 그래프를 보면 8월 18일과 19일에 이낙연 의원 언급량이 크게 상승했습니다. 8월 18일과 19일에 이낙연 의원을 언급한 트윗을 대상으로 로그 오즈비를 구해 어떤 단어가 많이 사용됐는지 알아보겠습니다.

#### 1. 날짜 분류, 단어별 빈도 구하기

```{r}
frequency_nak1819 <- word_tweet_raw %>%
  mutate(category = ifelse(date >= "2020-08-18" &
                           date <= "2020-08-19", "target", "etc")) %>%
  filter(candidate == "이낙연" & str_count(word) >= 2) %>%
  count(category, word, sort = T)
```


#### 2. 로그 오즈비 구하기

다음 코드의 출력 결과에서 `"음성판정"`, `"검사결과"` 등의 로그 오즈비가 높은 것을 보면 이날 이낙연 의원에게 코로나19 검사와 관련된 일이 있었던 것으로 보입니다.

```{r}
# Wide form으로 변환
wide_nak1819 <- frequency_nak1819 %>%
  pivot_wider(names_from = category,
              values_from = n,
              values_fill = list(n = 0))

# 로그 오즈비 변수 추가
wide_nak1819 <- wide_nak1819 %>%
  mutate(log_odds_ratio = log(((target + 1) / (sum(target + 1))) /
                                ((etc  + 1) / (sum(etc    + 1)))))
```

```{r}
# log_odds_ratio 높은 순 출력
wide_nak1819 %>%
  arrange(-log_odds_ratio) %>%
  head(20) %>%
  print(n = Inf)
```

<!-- ```{r echo=F} -->
<!-- # log_odds_ratio 높은 순 출력 -->
<!-- wide_nak1819 %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   head(10) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->


#### 3. 원문 살펴보기

2020년 8월 18일과 19일에 로그 오즈비가 가장 높은 `"다행입니다"`를 언급한 트윗을 추출해 내용을 살펴보겠습니다. 출력 결과를 보면 이날 이낙연 의원이 코로나19 검사 음성 판정을 받았다는 것을 알 수 있습니다.

```{r eval=F}
# 트윗 내용 확인
tweet %>%
  filter(date >= "2020-08-18" & date <= "2020-08-19" &
         candidate == "이낙연" & str_detect(text, "다행입니다")) %>%
  head(10) %>%
  pull(text)
```


```{r echo=F}
# 트윗 내용 확인
tweet %>%
  filter(date >= "2020-08-18" & date <= "2020-08-19" &
         candidate == "이낙연" &
         str_detect(text, "다행입니다")) %>%
  head(3) %>%
  pull(text)
```

> [편집] 출력 결과 생략, 빈줄 삭제

<br>

> [참고] 아래 URL에 접속해 구글 검색 결과를 보면 이낙연 의원이 2020년 8월 19일에 코로나19 검사 음성 판정을 받았다는 사실을 확인할 수 있습니다.

> [google.com/search?q=이낙연+음성%202020.08.19..2020.08.19](google.com/search?q=이낙연+음성%202020.08.19..2020.08.19)


## 8.3 감정 단어

두 후보를 언급한 트윗에 어떤 감정이 담겨 있는지 알아보겠습니다.

### 감정 단어 살펴보기

#### 1. 감정 점수, 감정 범주 부여하기

먼저 감정 사전을 이용해 트윗에 사용된 단어에 감정 점수를 부여하고, 감정 범주별로 어떤 단어가 많이 사용됐는지 살펴보겠습니다.

```{r eval=F}
# 감정 사전 불러오기
dic <- read_csv("files/knu_sentiment_lexicon.csv")
```

```{r echo=F}
# 감정 사전 불러오기
dic <- read_csv(here::here("files/knu_sentiment_lexicon.csv"))
```

```{r}
# 감정 점수 부여, 감정 극성 분류
word_tweet <- word_tweet_raw %>%
  left_join(dic, by = "word") %>%                             # 감정 점수 부여
  mutate(polarity = ifelse(is.na(polarity), 0, polarity),     # NA를 0으로 변환
         sentiment = ifelse(polarity ==  2, "긍정",           # 감정 범주 분류
                     ifelse(polarity == -2, "부정", "중립")))

```

#### 2. 자주 언급한 감정 단어 살펴보기

어떤 감정 단어가 트윗에 많이 사용됐는지 알아보겠습니다. 후보 이름은 각 후보 데이터에서 가장 많이 언급되지만 트윗을 해석하는데 도움이 되지 않기 때문에 제거하겠습니다. 그런 다음 각 후보의 감정 범주별 단어 빈도를 구해 가장 많이 사용된 긍정 단어와 부정 단어를 10개씩 추출하겠습니다.

```{r}
# 자주 언급한 단어 추출
top10_word <- word_tweet %>%

  # 불용어 제거
  filter(!(candidate == "이낙연" & str_detect(word, "이낙연")) &
         !(candidate == "이재명" & str_detect(word, "이재명"))) %>%

  filter(str_count(word) >= 2) %>%
  count(candidate, sentiment, word) %>%

  group_by(candidate, sentiment) %>%
  slice_max(n, n = 10, with_ties = F)

top10_word
```

#### 3. 막대 그래프 만들기

앞에서 생성한 `top10_word`를 이용해 막대 그래프를 만들겠습니다.

```{r}
ggplot(top10_word, aes(x = reorder_within(word, n, candidate),
                       y = n,
                       fill = sentiment)) +
  geom_col() +
  coord_flip() +
  facet_wrap(candidate ~ sentiment,  # 후보, 감정 범주별 그래프 생성
             scales = "free") +
  scale_x_reordered()
```


#### 그래프 다듬기

`ggplot2` 패키지의 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.
```{r fig.height=8, fig.width=8}
col_sentiment <- c("#619CFF", "#00BA38", "#F8766D")  # 감정 색깔 목록
order_sentiment <- c("긍정", "중립", "부정")         # 감정 범주 목록

# 그래프 순서 지정
top10_word$sentiment <- factor(top10_word$sentiment,
                               levels = order_sentiment)

ggplot(top10_word, aes(x = reorder_within(word, n, candidate),
                       y = n,
                       fill = sentiment)) +
  geom_col() +
  coord_flip() +
  facet_wrap(candidate ~ sentiment,
             scales = "free") +
  scale_x_reordered() +
  scale_fill_manual(values = col_sentiment) +
  
  labs(title = "차기 대선주자 감정 단어",
       subtitle = "감정 극성별 빈도 Top 10",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom")  # 범례 위치
```

출력한 그래프를 보면 후보에 따라 자주 언급한 감정 단어가 다르다는 것을 알 수 있습니다. 예를 들어 긍정 단어를 보면 이낙연 의원은 `"소중한"`, `"훌륭한"` `"감사"`등의 빈도가 높은 반면 이재명 경기도지사는 `"잘하는"`, `"젊은"`, `"시원하게"` 등의 빈도가 높습니다. 이런 감정 단어를 보면 각 후보에게 어떤 이미지가 있는지 가늠할 수 있습니다.

## 8.4 감정 경향

두 후보를 언급한 트윗이 전반적으로 어떤 감정 경향을 띄는지 알아보겠습니다.

### 8.4.1 트윗 감정 점수 구하기

`word_tweet`의 `status_id`는 트윗별로 서로 다른 값을 지닌 고유값입니다. `word_tweet`을 `candidate`, `status_id`별로 분리한 다음 `polarity`를 합산해 감정 점수를 담은 `score`를 만들겠습니다. 그런 다음 트윗 원본이 들어있는 `tweet`에 결합하겠습니다. `hist()`를 이용해 히스토그램을 만들면 감정 점수가 0에 가까운 트윗이 많고, 감정 점수가 높아지거나 낮아질수록 빈도가 점차 줄어든다는 것을 알 수 있습니다.

```{r fig.width=6, fig.height=4}
# 트윗 감정 점수 구하기
sentiment_tweet <- word_tweet %>%
  group_by(candidate, status_id) %>%
  summarise(score = sum(polarity)) %>%
  ungroup()

# 트윗 원문에 감정 점수 결합
tweet <- tweet %>%
  left_join(sentiment_tweet, by = c("candidate", "status_id"))

# 감정 점수 히스토그램
hist(tweet$score)
```

### 8.4.2 전반적인 감정 경향 살펴보기

#### 확률 밀도 함수 그래프 만들기

감정 점수를 이용해 **확률 밀도 함수 그래프(Density plot)**를 만들어 전반적으로 어떤 감정을 담은 트윗이 많은지 살펴보겠습니다.

`ggplot2` 패키지의 `geom_density()`를 이용하면 확률 밀도 함수 그래프를 만들 수 있습니다. 다음 코드의 `geom_density()`에서 `adjust`는 띠너비(bandwidth)를 조정해 그래프를 평평하게 만드는 기능을 합니다. `alpha`는 투명도를 조정해 그래프가 중첩된 부분을 드러내는 기능을 합니다.

```{r fig.width=6, fig.height=4}
ggplot(tweet, aes(x = score, fill = candidate)) +
  geom_density(adjust = 2, alpha = 0.6)
```

#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
ggplot(tweet, aes(x = score, fill = candidate)) +
  geom_density(adjust = 2, alpha = 0.6) +
  geom_vline(xintercept = 0,                   # 0점 위 세로선 표시
             linetype = "dashed",              # 점선 표시
             size = 0.5,
             alpha = 0.5) +
  
  scale_x_continuous(breaks = c(-5:5),         # x축 범위
                     limits = c(-5, 5)) +      # x축 간격
  scale_fill_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 감정 점수 분포",
       subtitle = "2020.8.13 ~ 2020.8.21",
       y = NULL, fill = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom",
        panel.grid = element_blank())          # 격자 삭제
```

출력한 그래프를 보면 이재명 경기도지사는 이낙연 의원에 비해 감정 점수가 낮거나 0에 가까운 트윗이 많은 반면, 이낙연 의원은 이재명 경기도지사에 비해 감정 점수가 높은 트윗이 많다는 것을 알 수 있습니다.

### 8.4.3 일자별 감정 경향 살펴보기

#### 일자별 확률 밀도 함수 그래프 만들기

`facet_wrap()`을 이용해 확률 밀도 함수 그래프를 날짜별로 만들어 두 후보를 언급한 트윗의 감정 경향이 어떻게 다른지 살펴보겠습니다.

```{r}
ggplot(tweet, aes(x = score, fill = candidate)) +
  geom_density() +
  facet_wrap(~ date)
```


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
ggplot(tweet, aes(x = score, fill = candidate)) +
  geom_density(adjust = 2,
               alpha = 0.6) +
  
  geom_vline(xintercept = 0,
             linetype = "dashed",
             size = 0.5,
             alpha = 0.5) +
  
  facet_wrap(~ str_remove(date, "2020-"),                  # x축 년도 삭제
             scales = "free_y",
             ncol = 3,
             strip.position = "bottom") +
  
  scale_x_continuous(breaks = c(-5:5),
                     limits = c(-5, 5)) +
  scale_fill_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 일자별 감정 점수 분포",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +

  theme_bw(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom",
        panel.grid = element_blank(),
        axis.ticks = element_blank(),                      # 축 눈금 삭제
        axis.text = element_blank(),                       # 축 삭제
        strip.background = element_rect(colour = "black",  # 패널명 배경
                                        fill = "white"))  
```

출력한 그래프를 보면 두 후보를 언급한 트윗의 감정 경향이 날짜별로 다릅니다. 트윗의 양을 상대적으로 비교해보면, 대부분의 날짜에 이낙연 의원은 긍정적인 트윗이 많고, 이재명 경기도지사는 부정적인 트윗이 많습니다. 특히 8월 16일과 8월 17일은 이낙연 의원을 긍정적으로 언급한 트윗이 많습니다. 반면 8월 18일의 경우 이낙연 의원은 감정 점수가 낮거나 0점에 가까운 트윗이 많고, 이재명 경기도지사는 다른 날짜에 비해 감정 점수가 높은 트윗이 많습니다.


### 8.4.4 감정 범주 살펴보기

트윗을 감정 점수 기준으로 긍정, 중립, 부정으로 분류해 빈도를 구한 다음 두 후보를 언급한 트윗의 감정 범주 비중을 살펴보겠습니다.

#### 1. 감정 범주별 빈도와 비율 구하기

```{r}
# 감정 분류 변수 생성
tweet <- tweet %>%
  mutate(sentiment = ifelse(score >= 1, "긍정",
                     ifelse(score <= -1, "부정", "중립")))

# 후보, 감정별 빈도 및 비율
frequency_sentiment <- tweet %>%
  group_by(candidate) %>%
  count(sentiment) %>%
  mutate(ratio = n/sum(n))
```


```{r eval=F}
frequency_sentiment
```

```{r echo=F}
frequency_sentiment %>% print(n = Inf)
```


#### 2. 감정 범주 빈도 막대 그래프 만들기

앞에서 생성한 `frequency_sentiment`를 이용해 막대 그래프를 만들겠습니다.

```{r}
ggplot(frequency_sentiment, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_col() +
  facet_wrap(~ candidate)
```


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
# 순서 설정
frequency_sentiment$sentiment <- factor(frequency_sentiment$sentiment,
                                        levels = order_sentiment)
```

```{r}
library(scales)
ggplot(frequency_sentiment, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_col(show.legend = F) +                   
  facet_wrap(~ candidate) +
  geom_text(aes(label = comma(n)), vjust = -0.5) +
  
  ylim(0, 3500) +
  scale_fill_manual(values = col_sentiment) +   # 막대 색깔
  
  labs(title = "차기 대선주자 트윗 감정 빈도",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL) +
  
  theme_bw(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12), 
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank())
```

출력한 그래프를 보면 트윗이 주로 어떤 감정을 담고 있는지 알 수 있습니다. 두 후보 모두 중립 트윗이 가장 많지만, 이낙연 의원은 긍정 트윗과 부정 트윗의 양이 비슷한 반면, 이재명 경기도지사는 긍정 트윗보다 부정 트윗의 양이 더 많습니다.


#### 3. 감정 범주 비율 누적 막대 그래프 만들기

`frequency_sentiment`를 이용해 감정 범주 비율을 누적한 막대 그래프를 만들겠습니다.

```{r fig.width=6, fig.height=4}
ggplot(frequency_sentiment, aes(x = candidate, y = ratio, fill = sentiment)) +
  geom_col()
```


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

> [참고] `geom_text()`에 적용한 `percent()`는 값에 `%`를 붙여 비율로 표현하는 `scale` 패키지 함수 입니다. `accuracy`는 반올림할 자릿수를 정하는 기능을 합니다.

```{r fig.width=8, fig.height=4}
# 막대 누적 순서 지정
frequency_sentiment$sentiment <- factor(frequency_sentiment$sentiment,
                                        levels = rev(order_sentiment))

ggplot(frequency_sentiment, aes(x = candidate, y = ratio, fill = sentiment)) +
  geom_col(show.legend = F, width = 0.7) +
  
  geom_text(aes(label = paste(sentiment, percent(ratio, accuracy = 0.1))),
            position = position_stack(vjust = 0.5)) +     # 수직 위치
  coord_flip() +
  scale_x_discrete(limits = c("이재명", "이낙연")) +
  
  labs(title = "차기 대선주자 트윗 감정 비율",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_void(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom",
        axis.text.y = element_text(size = 12),            # y축 글자 크기
        plot.margin = margin(1, 1, 1, 1, unit = "line"))  # 여백 상우하좌, 단위
```

> [편집] 모든 텍스트 표현되도록 그래프 크기 조정

출력한 그래프를 보면 트윗의 감정 비중을 알 수 있습니다. 두 후보 모두 중립 트윗의 비율이 60%대로 가장 많습니다. 이낙연 의원은 긍정 트윗과 부정 트윗의 비율이 비슷한 반면, 이재명 경기도지사는 부정 트윗 비율이 긍정 트윗 비율보다 더 많습니다.



## 8.5 감정 추이

두 후보의 트윗 감정 범주 빈도가 날짜별로 어떻게 다른지, 감정 추이를 살펴보겠습니다.

### 8.5.1 트윗 감정 추이 선 그래프

트윗을 `date`, `candidate`, `sentiment`별로 분류해 빈도를 구한 다음 선 그래프를 만들겠습니다.

```{r}
# 날짜, 후보, 감정별 빈도
sentiment_candidate <- tweet %>%
  count(date, candidate, sentiment)

sentiment_candidate

## 트윗 감정 추이 선 그래프
ggplot(sentiment_candidate, aes(x = date, y = n, col = sentiment)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ candidate, nrow = 2, scales = "free_x")
```

출력한 그래프를 보면 중립 트윗의 빈도가 압도적으로 많아 긍정 트윗과 부정 트윗의 추이가 잘 표현되지 않습니다. `sentiment_candidate`에서 중립 트윗을 제외한 다음 다시 선 그래프를 만들겠습니다.

```{r}
# 중립 트윗 제외
tweet_polar <- sentiment_candidate %>%
  filter(sentiment != "중립")

ggplot(tweet_polar, aes(x = date, y = n, col = sentiment)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ candidate, nrow = 2, scales = "free_x")
```

#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
# 색깔 목록 생성
col_polar <- c("#619CFF", "#F8766D")

ggplot(tweet_polar, aes(x = date, y = n, col = sentiment)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ candidate, nrow = 2, scales = "free_x") +
  
  scale_x_date(date_labels = "%m/%d",
               date_breaks  = "1 day") +
  ylim(0, 250) +
  scale_color_manual(values = col_polar) +
  
  labs(title = "차기 대선주자 트윗 감정 추이",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, col = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.grid.minor.x = element_blank(),
        panel.spacing = unit(2, "lines"))  # 그래프 간격
  
```

출력한 그래프를 보면 두 후보를 언급한 트윗의 감정 빈도 추이를 알 수 있습니다. 이낙연 의원은 전반적으로 긍정, 부정 트윗의 빈도와 변화량이 비슷한데, 8월 18일에만 유독 부정 트윗의 빈도가 상승했습니다. 이재명 경기도지사는 일관되게 부정 트윗이 많고, 긍정, 부정 트윗의 변화량도 비슷합니다.


### 8.5.2 트윗 감정 추이 영역 차트

트윗 감정 추이의 차이를 보다 잘 드러내기 위해 `tweet_polar`를 이용해 영역 차트를 만들겠습니다.

```{r}
ggplot(tweet_polar, aes(x = date, y = n, fill = sentiment)) +
  geom_area(position = "dodge", alpha = 0.7) +
  facet_wrap(~ candidate, nrow = 2, scales = "free_x")
```

#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

```{r}
ggplot(tweet_polar, aes(x = date, y = n, fill = sentiment)) +
  geom_area(position = "dodge", alpha = 0.7) +
  facet_wrap(~ candidate, nrow = 2, scales = "free_x") +
  
  scale_x_date(date_labels = "%m/%d", date_breaks  = "1 day") +
  ylim(0, 250) +
  scale_fill_manual(values = col_polar) +
  
  labs(title = "차기 대선주자 트윗 감정 추이",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_gray(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12), 
        panel.grid = element_blank(),
        panel.spacing = unit(2, "lines"))  # 그래프 간격 띄우기
```

출력한 그래프를 보면 두 후보의 감정 추이를 쉽게 파악할 수 있습니다. 이낙연 의원은 전반적으로 긍정, 부정 트윗의 비중이 비슷합니다. 8월 13, 17, 20, 21일은 긍정 트윗이 조금 더 많았고, 8월 18일은 부정 트윗이 유독 많았습니다. 반면 이재명 경기도지사는 일관되게 부정 트윗의 양이 더 많았습니다.


## 8.6 긍정, 부정 트윗 주요 단어 비교

로그 오즈비를 이용해 두 후보를 언급한 긍정 트윗과 부정 트윗에서 상대적으로 어떤 단어를 많이 사용했는지 비교해보겠습니다.

### 8.6.1 긍정 트윗 주요 단어 비교

#### 1. 감정 및 단어별 빈도 구하기

두 후보의 긍정 트윗에 사용된 단어가 어떻게 다른지 비교하겠습니다. `8.2.1`에서 트윗을 띄어쓰기 기준으로 토큰화한 `word_tweet_raw`를 이용해 두 글자 이상 한글 단어를 추출하겠습니다. 그런 다음 트윗의 감정 점수와 감정 범주가 들어있는 `tweet`을 결합하겠습니다.

```{r}
# 두 글자 이상 한글 단어 추출
word_sentiment_tweet <- word_tweet_raw %>%
  filter(str_detect(word, "[가-힣]") &
         str_count(word) >= 2) %>%

  # tweet 결합
  left_join(tweet %>% select(candidate, status_id, score, sentiment),
            by = c("candidate", "status_id"))
```

```{r eval=F}
glimpse(word_sentiment_tweet)
```

```{r echo=F}
glimpse(word_sentiment_tweet, width = 60)
```

`word_sentiment_tweet`을 이용해 감정 범주 및 단어별 빈도를 구하겠습니다. 우선 한 트윗에 같은 단어가 여러 번 사용돼 로그 오즈비가 높아지는 문제를 막기 위해 트윗별로 중복 단어를 제거하겠습니다. 그런 다음 `candidate`, `sentiment`, `word`별 빈도를 구하겠습니다.

```{r}
# 감정 범주 및 단어별 빈도 구하기
frequency_sentiment <- word_sentiment_tweet %>%  

  group_by(status_id) %>%                        # 트윗별 분리
  distinct(word, .keep_all = T) %>%              # 중복 단어 제거
  ungroup() %>%

  count(candidate, sentiment, word, sort = T)

frequency_sentiment
```


#### 2. 로그 오즈비 구하기

`frequency_sentiment`에서 긍정 트윗만 추출한 다음 후보 이름을 제거하겠습니다. 후보 이름을 제거하는 이유는 빈도는 높지만 해석하는데 도움이 되지 않기 때문입니다. 그런 다음 Wide from으로 변환해 로그 오즈비를 구하겠습니다. 분모에 이재명 경기도지사, 분자에 이낙연 의원의 단어 빈도를 놓고 로그 오즈비를 구했으므로, 이낙연 의원을 언급한 트윗에서 많이 사용된 단어일수록 `log_odds_ratio`가 큰 값을 지니게 됩니다.

```{r}
# Wide form으로 변환
wide_pos <- frequency_sentiment %>%
  filter(sentiment == "긍정" & !str_detect(word, "이낙연|이재명")) %>%
  pivot_wider(names_from = candidate,
              values_from = n,
              values_fill = list(n = 0))

# 로그 오즈비 구하기
log_odds_pos <- wide_pos %>%
  mutate(log_odds_ratio = log(((이낙연 + 1) / (sum(이낙연 + 1))) /
                              ((이재명 + 1) / (sum(이재명 + 1)))))
```


#### 3. 불용어 목록 만들기

`log_odds_pos`에서 로그 오즈비 기준 상하위 15개 단어를 추출해 내용을 확인한 다음 불용어 목록을 만들겠습니다.

```{r eval=F}
# 불용어 확인
log_odds_pos %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 15, with_ties = F) %>% 
  select(word) %>% 
  print(n = Inf)
```

```{r echo=F}
# 불용어 확인
log_odds_pos %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 15, with_ties = F) %>% 
  select(word) %>% 
  print(n = 5)
```


<!-- ```{r eval=F} -->
<!-- # 불용어 확인 -->
<!-- log_odds_pos %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 15 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 15) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   select(word) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- # 불용어 확인 -->
<!-- log_odds_pos %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 15 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 15) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   select(word) %>%  -->
<!--   print(n = 5) -->
<!-- ``` -->




```{r}
# 불용어 목록 생성
stopword_pos <- c("것이고", "그건", "그는")
```


#### 4. 막대 그래프 만들기

불용어를 제외하고 로그 오즈비 기준 상하위 10개 단어를 추출해 막대 그래프를 만들겠습니다.

```{r}
# 로그 오즈비 상하위 10개 단어 추출
top10_pos <- log_odds_pos %>%
  filter(!word %in% stopword_pos) %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 10, with_ties = F)

# 막대 그래프 생성
ggplot(top10_pos, aes(x = reorder(word, log_odds_ratio),
                      y = log_odds_ratio,
                      fill = candidate)) +
  geom_col() +
  coord_flip()
```


<!-- ```{r} -->
<!-- # 로그 오즈비 상하위 10개 단어 추출 -->
<!-- top10_pos <- log_odds_pos %>% -->
<!--   filter(!word %in% stopword_pos) %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 10 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 10) %>% -->
<!--   mutate(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>% -->
<!--   arrange(-log_odds_ratio) -->

<!-- # 막대 그래프 생성 -->
<!-- ggplot(top10_pos, aes(x = reorder(word, log_odds_ratio), -->
<!--                       y = log_odds_ratio, -->
<!--                       fill = candidate)) + -->
<!--   geom_col() + -->
<!--   coord_flip() -->
<!-- ``` -->


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다. 출력한 그래프를 보면 두 후보를 언급한 긍정 트윗에서 상대적으로 어떤 단어를 많이 사용했는지 알 수 있습니다. 뒤에서 주요 단어가 사용된 트윗을 추출해 단어가 어떤 의미로 사용됐는지 살펴보겠습니다.

```{r}
ggplot(top10_pos, aes(x = reorder(word, log_odds_ratio),
                      y = log_odds_ratio,
                      fill = candidate)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 긍정 트윗 주요 단어",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12))
```



#### 4. 롤리팝 차트 만들기

선분과 점을 이용해 막대 사탕 모양으로 표현한 그래프를 **롤리팝 차트(Lollipop chart)**라 합니다. 롤리팝 차트는 값을 세밀하게 표현하기 때문에 여러 값의 차이를 표현할 때 유용합니다.

단어 로그 오즈비를 이용해 롤리팝 차트를 만들겠습니다. `ggplot2` 패키지의 `geom_segment()`와 `geom_point()`를 이용하면 롤리팝 차트를 만들 수 있습니다. 먼저 `geom_segment()`에 x, y축의 시작점과 끝점을 지정해 선분으로 연결합니다. 그런 다음 `geom_point()`를 이용해 점을 추가하면 롤리팝 차트가 완성됩니다.

```{r}
# 단어 순서 지정해 factor 타입으로 변환
top10_pos <- top10_pos %>%
  ungroup() %>%
  mutate(word = reorder(word, log_odds_ratio))

# 롤리팝 차트 생성
ggplot(top10_pos, aes(x = word,
                      y = log_odds_ratio,
                      col = candidate)) +
  geom_segment(aes(x = word,                  # x축 시작점
                   xend = word,               # x축 끝점
                   y = 0,                     # y축 시작점
                   yend = log_odds_ratio)) +  # y축 끝점
  geom_point() +
  coord_flip()
```

#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다. 다음 코드로 만든 그래프를 보면 로그 오즈비의 차이가 세밀하게 표현되어 단어 간 차이를 쉽게 비교할 수 있음을 알 수 있습니다.

```{r}
ggplot(top10_pos, aes(x = word,
                      y = log_odds_ratio,
                      col = candidate)) +
  
  geom_segment(aes(x = word,
                   xend = word,
                   y = 0,
                   yend = log_odds_ratio),
               size = 1.1) +
  
  geom_point(size = 3.5) +
  coord_flip() +
  scale_color_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 긍정 트윗 주요 단어",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, col = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12)) 
```


#### 5. 원문 살펴보기

로그 오즈비가 높은 단어가 사용된 트윗을 추출해 내용을 살펴보겠습니다.


#### 이낙연 의원 긍정 트윗

**7.2.3**에서 만든 `find_word()`를 이용해 이낙연 의원 긍정 트윗에서 관심 단어가 사용된 트윗을 추출해 내용을 살펴보겠습니다.


```{r}
# 이낙연 의원 긍정 트윗 추출
pos_nak <- tweet %>%
  filter(sentiment == "긍정" & candidate == "이낙연") %>%
  arrange(-score)
```



**"음성"** : 로그 오즈비가 가장 높은 `"음성"`이 사용된 트윗을 보면 대부분 이낙연 의원이 코로나19 검사 결과 음성 판정을 받아 다행이라는 내용임을 알 수 있습니다.

```{r echo=F}
library(crayon)
source(here::here("rmd_etc/func_find_word.R"))
```

```{r eval=F}
pos_nak %>% find_word(x = text, keyword = "음성")
```

```{r echo=F}
pos_nak %>% find_word(x = text, keyword = "음성", n = 3)

```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "음성"


<br>

**"의원님"** : 로그 오즈비가 두 번째로 높은 `"의원님"`이 사용된 트윗을 보면 대부분 이낙연 의원을 응원하는 내용임을 알 수 있습니다.

```{r eval=F}
pos_nak %>% find_word(x = text, keyword = "의원님")
```

```{r echo=F}
pos_nak %>% find_word(x = text, keyword = "의원님", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "의원님"


#### 이재명 경기도지사 긍정 트윗

이재명 경기도지사 긍정 트윗에서 관심 단어가 사용된 트윗을 추출해 내용을 살펴보겠습니다.

```{r}
# 이재명 경기도지사 긍정 트윗 추출
pos_jae <- tweet %>%
  filter(sentiment == "긍정" & candidate == "이재명") %>%
  arrange(-score)
```


**"경기도"** : 로그 오즈비가 가장 높은 `"경기도"`가 사용된 트윗을 보면 대부분 이재명 경기도지사가 경기도에서 시행한 정책을 다룬 내용임을 알 수 있습니다.

```{r eval=F}
pos_jae %>% find_word(x = text, keyword = "경기도")
```

```{r echo=F}
pos_jae %>% find_word(x = text, keyword = "경기도", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "경기도"

<br>

**"이익을"** : 로그 오즈비가 두 번째로 높은 `"이익을"`이 사용된 트윗을 보면 대부분 이재명 경기도지사와 관련된 정치적 이익을 다룬 내용들입니다.

```{r eval=F}
pos_jae %>% find_word(x = text, keyword = "이익을")
```

```{r echo=F}
pos_jae %>% find_word(x = text, keyword = "이익을", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "이익을"

앞에서 출력한 트윗을 보면 긍정 트윗에서 추출했는데도 부정적인 내용이 많이 포함되어 있습니다. 이는 이재명 경기도지사를 언급한 트윗의 감정 점수가 대부분 낮기 때문입니다. 다음 코드의 출력 결과를 보면 `"이익을"`이 사용된 긍정 트윗의 감정 점수가 전반적으로 낮다는 것을 알 수 있습니다.


# "이익을" 언급한 트윗

```{r}
pos_jae %>%
  filter(str_detect(text, "이익을")) %>%
  select(score)
```

# "이익을" 언급하지 않은 트윗
```{r}
pos_jae %>%
  filter(!str_detect(text, "이익을")) %>%
  select(score)
```


### 8.6.2 부정 트윗 주요 단어 비교

이번에는 두 후보의 부정 트윗에 사용된 단어를 비교하겠습니다.

#### 1. 로그 오즈비 구하기

감정 범주별 단어 빈도를 담은 `frequency_sentiment`에서 부정 트윗의 단어를 추출해 로그 오즈비를 구하겠습니다.

```{r}
# Wide form으로 변환
wide_neg <- frequency_sentiment %>%
  filter(sentiment == "부정" & !str_detect(word, "이낙연|이재명")) %>%
  pivot_wider(names_from = candidate,
              values_from = n,
              values_fill = list(n = 0))

# 로그 오즈비 구하기
log_odds_neg <- wide_neg %>%
  mutate(log_odds_ratio = log(((이낙연 + 1) / (sum(이낙연 + 1))) /
                              ((이재명 + 1) / (sum(이재명 + 1)))))
```


#### 2. 불용어 목록 만들기

로그 오즈비 기준 상하위 15개 단어를 추출해 내용을 확인한 다음 불용어 목록을 만들겠습니다.

```{r eval=F}
# 불용어 확인
log_odds_neg %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 15, with_ties = F) %>% 
  select(word) %>% 
  print(n = Inf)
```

```{r echo=F, output.lines = 9}
log_odds_neg %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 15, with_ties = F) %>% 
  select(word) %>% 
  print(n = Inf)
```

```{r echo=F, output.lines = 20:24}
log_odds_neg %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 15, with_ties = F) %>% 
  select(word) %>% 
  print(n = Inf)
```


<!-- ```{r eval=F} -->
<!-- # 불용어 확인 -->
<!-- log_odds_neg %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 15 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 15) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->

<!-- ```{r echo=F, output.lines = 1:8} -->
<!-- log_odds_neg %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 15 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 15) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->

<!-- ```{r echo=F, output.lines = 29:33} -->
<!-- log_odds_neg %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 15 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 15) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   print(n = Inf) -->

<!-- ``` -->

> [편집] 가운데 ... 중복 삭제

출력 결과를 보면 이재명 경기도지사를 언급한 트윗에서 `"지금껏"`, `"겪어보지"`, `"쓰나미급"`이 많이 사용됐음을 알 수 있습니다. 이는 이재명 경기도지사가 코로나19 관련 기자회견에서 "지금껏 겪어보지 못한 쓰나미급 대충격 시작될 것"이라는 표현을 사용한 적이 있는데, 이 일이 트위터에서 많이 회자되었기 때문입니다. 다음 코드의 출력 결과를 보면 이 표현을 지적한 트윗이 많다는 것을 알 수 있습니다.

```{r eval=F}
tweet %>%
  filter(candidate == "이재명") %>%
  find_word(x = text, keyword = "쓰나미급")
```

```{r echo=F}
tweet %>%
  filter(candidate == "이재명") %>%
  find_word(x = text, keyword = "쓰나미급", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "쓰나미급"

이 단어들은 같은 문장에서 나왔으므로 `"쓰나미급"`만 남겨두고 분석에서 제외하도록 불용어 목록으로 만들겠습니다. 의미를 파악하기 어려운 `"그건"`, `"주고"`도 불용어 목록에 포함하겠습니다.

```{r}
# 불용어 목록 생성
stopword_neg <- c("지금껏", "겪어보지", "대충격", "시작될", "그건", "주고")
```

#### 3. 막대 그래프 만들기

불용어를 제외하고 로그 오즈비 기준 상하위 10개 단어를 추출해 막대 그래프를 만들겠습니다.


```{r}
# 로그 오즈비 상하위 10개 단어 추출
top10_neg <- log_odds_neg %>%
  filter(!word %in% stopword_neg) %>%
  group_by(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>%
  slice_max(abs(log_odds_ratio), n = 10, with_ties = F)

# 막대 그래프 생성
ggplot(top10_neg, aes(x = reorder(word, log_odds_ratio),
                      y = log_odds_ratio,
                      fill = candidate)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 부정 트윗 주요 단어",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, fill = NULL) +
  
  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12))
```


<!-- ```{r} -->
<!-- # 로그 오즈비 상하위 10개 단어 추출 -->
<!-- top10_neg <- log_odds_neg %>% -->
<!--   filter(!word %in% stopword_neg) %>% -->
<!--   filter(rank(log_odds_ratio, ties.method = "first") <= 10 | -->
<!--          rank(-log_odds_ratio, ties.method = "first") <= 10) %>% -->
<!--   mutate(candidate = ifelse(log_odds_ratio > 0, "이낙연", "이재명")) %>% -->
<!--   arrange(-log_odds_ratio) -->


<!-- # 막대 그래프 생성 -->
<!-- ggplot(top10_neg, aes(x = reorder(word, log_odds_ratio), -->
<!--                       y = log_odds_ratio, -->
<!--                       fill = candidate)) + -->
<!--   geom_col() + -->
<!--   coord_flip() + -->
<!--   scale_fill_manual(values = col_candidate) + -->
<!--   theme_minimal(12) + -->
<!--   theme(text = element_text(family = "nanumgothic")) + -->
<!--   labs(title = "차기 대선주자 부정 트윗 주요 단어", -->
<!--        subtitle = "2020.8.13 ~ 2020.8.21", -->
<!--        x = NULL, y = NULL, fill = NULL) -->
<!-- ``` -->



#### 4. 롤리팝 차트 만들기

단어의 로그 오즈비를 보다 세밀하게 표현하기 위해 롤리팝 차트를 만들겠습니다.

```{r}
# 단어 순서 지정해 factor 타입으로 변환
top10_neg <- top10_neg %>%
  ungroup() %>%
  mutate(word = reorder(word, log_odds_ratio))

# 롤리팝 차트 생성
ggplot(top10_neg, aes(x = word,
                      y = log_odds_ratio,
                      col = candidate)) +
  
  geom_segment(aes(x = word,
                   xend = word,
                   y = 0,
                   yend = log_odds_ratio),
               size = 1.1) +
  
  geom_point(size = 3.5) +
  coord_flip() +
  scale_color_manual(values = col_candidate) +
  
  labs(title = "차기 대선주자 부정 트윗 주요 단어",
       subtitle = "2020.8.13 ~ 2020.8.21",
       x = NULL, y = NULL, col = NULL) +

  theme_minimal(12) +
  theme(text = element_text(family = "nanumgothic"),
        plot.title = element_text(size = 14, face = "bold"),
        plot.subtitle = element_text(size = 12))
```



#### 5. 원문 살펴보기

로그 오즈비가 높은 단어가 사용된 트윗의 내용을 살펴보겠습니다. 먼저 각 후보의 부정 트윗을 추출하겠습니다.

```{r}
# 이낙연 의원 부정 트윗 추출
neg_nak <- tweet %>%
  filter(sentiment == "부정" & candidate == "이낙연") %>%
  arrange(-score)

# 이재명 경기도지사 부정 트윗 추출
neg_jae <- tweet %>%
  filter(sentiment == "부정" & candidate == "이재명") %>%
  arrange(-score)
```


#### 이낙연 의원 부정 트윗



**"음성"** : 이낙연 의원 부정 트윗에서 로그 오즈비가 가장 높은 `"음성"`을 언급한 트윗을 추출하겠습니다. 출력 결과를 보면 이낙연 의원이 코로나19 확진 판정을 받을까봐 걱정하며 안타까운 심정을 표현한 내용이 많다는 것을 알 수 있습니다.

```{r eval=F}
neg_nak %>% find_word(x = text, keyword = "음성")
```

```{r echo=F}
neg_nak %>% find_word(x = text, keyword = "음성", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "음성"

<br>

**"의원님"** : 두 번째로 로그 오즈비가 높은 `"의원님"`을 언급한 트윗을 보면 주로 이낙연 의원의 정치 활동에 방해가 되는 일을 비판하는 내용임을 알 수 있습니다.

```{r eval=F}
neg_nak %>% find_word(x = text, keyword = "의원님")
```

```{r echo=F}
neg_nak %>% find_word(x = text, keyword = "의원님", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "의원님"


#### 이재명 경기도지사 부정 트윗

**"경기도"** : 이재명 경기도지사 부정 트윗에서 로그 오즈비가 가장 높은 `"경기도"`를 언급한 트윗을 추출하겠습니다. 출력 결과를 보면 주로 경기도 행정을 비판하는 내용으로 구성된다는 것을 알 수 있습니다.

```{r eval=F}
neg_jae %>% find_word(x = text, keyword = "경기도")
```


```{r echo=F}
neg_jae %>% find_word(x = text, keyword = "경기도", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "경기도"

<br>

**"쓰나미급"** : 두 번째로 로그 오즈비가 높은 `"쓰나미급"`이 사용된 트윗을 보면 대부분 이재명 경기도지사가 '지금껏 겪어보지 못한 쓰나미급 대충격 시작될 것'이라고 표현한 것을 비판하는 내용이 주를 이루고 있습니다.

```{r eval=F}
neg_jae %>% find_word(x = text, keyword = "쓰나미급")
```

```{r echo=F}
neg_jae %>% find_word(x = text, keyword = "쓰나미급", n = 3)
```

> [편집] 결과 생략 표시, 폰트 적용 수정 - "쓰나미급"


#### SNS 데이터로 여론 파악하기

트위터 데이터를 이용해 사람들이 차기 대선 후보들을 어떻게 생각하는지 알아봤습니다. 두 후보의 트윗 언급량 추이를 알아보고, 언급량이 급상승한 특정 날짜의 이슈를 살펴봤습니다. 감정 분석을 이용해 두 후보에게 어떤 이미지가 있는지, 감정 추이는 어떻게 다른지 비교해봤습니다.

SNS 데이터를 분석하면 여론 동향을 파악할 수 있습니다. 특히 감정 분석을 하면 민감한 주제에 관해 사람들이 어떤 생각을 하는지 다양한 입장을 파악하는데 도움이 됩니다. 하지만 SNS에는 주제와 관련 없는 광고나 여론을 왜곡하려는 의도로 작성한 글도 많기 때문에 분석에 앞서 신중하게 분석 대상을 선별해야 합니다. 그래야만 텍스트의 의미를 분명하게 이해하고 다수의 의견을 골고루 살펴볼 수 있습니다.

